# 项目速述
- 这是一个中文 AI 客服助手（CLI 入口 `python main.py`），基于 LangChain + ChatTongyi，结合检索（LanceDB 向量 + BM25）与工具调用，回答用户问题。
- 工具通过 MCP 暴露：MySQL 查询（订单状态、公司信息）和飞书告警；客服回复会带“依据”片段，缺信息时先澄清。
- 对话链路：构建系统提示 + 历史 + 检索结果 → LLM 生成 → 若触发工具则执行并再生成最终答复；最终答复再经“升级决策智能体”判定是否要走飞书告警（多通道可扩展）。
- 代码结构：`app/large_language_model.py`（主链路与决策调用）、`app/vector_db.py`（检索融合）、`agents/alert_agent.py`（告警决策智能体）、`mcp_service/*`（MCP 工具与路由）。

# MS自述（示例）
我做了一个中文 AI 客服助手：入口是 CLI，模型用 ChatTongyi，检索层用 LanceDB 向量 + BM25 融合，工具通过 MCP 调 MySQL 查订单/公司信息；回复会带依据。我们把“是否转人工/发飞书”拆成一个独立决策智能体，输出 JSON（escalate + reason + channels），再由路由器调用对应的 MCP 通道（当前是飞书，未来可扩展邮件等）。主流程简洁：生成答复→执行工具→再生成最终答复→决策是否告警。

# MS官可能追问
- 为什么把“是否转人工”拆成独立智能体，而不是直接让主模型用工具调用？怎么做输出格式约束和兜底？
- 检索融合怎么做的？LanceDB 向量 + BM25 如何排序/截断？遇到冷启动或无检索结果时怎么回复？
- MCP 工具的作用和好处？为什么用 MultiServerMCPClient 启两个进程而不是合并？
- 工具调用失败或超时时怎么处理？会不会阻塞用户回复？错误如何反馈给用户？
- 决策智能体的 few-shot 设计，如何避免模型跑题、不输出 JSON？
- 飞书/未来多渠道告警的路由策略？如何扩展邮件/SMS？决策的 channels 如何默认/兜底？
- 对话历史如何截断，防止上下文过长？trim_messages 的策略是什么？
- 系统提示里限制 200 字和“依据”格式的目的是什么？如何保证回复长度？
- DashScope key 和数据库凭据现在硬编码/环境变量，如何在生产管理安全性？
- 检索数据存储在 LanceDB，本地路径在哪里？如何更新数据或避免数据不同步？
- 有没有测试/监控？如何本地验证工具调用和告警链路不误触发真实飞书？
- 如果用户输入空/噪声怎么办？当前逻辑如何处理空字符串或无效输入？
- 假如要改成 HTTP MCP 而不是 stdio，改动点在哪？***
